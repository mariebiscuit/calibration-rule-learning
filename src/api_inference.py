from typing import Tuple, List, Dict, Type
import json
import os
from tqdm import tqdm
import pandas as pd
import copy
import re

from datasets import Dataset

from preprocess import format_shape
from utils.api_utils import get_together_completion, get_chatcompletion


def query_together_completion(model_id: str, 
                                dataset: Type[Dataset], 
                                uid: str,
                                pre_answer_token: str = "->", 
                                get_logprobs: bool=False):

    if not os.path.isdir(f'./results/raw_results/{uid}'):
        os.mkdir(f'./results/raw_results/{uid}')

    for concept in dataset['concepts']:
        output = {k: [] for k in ['top_ans', 'mass_ans', 'raw_true_mass', 'raw_false_mass']}
        concept_dataset = dataset.filter(lambda x: x['concepts'] == concept)
        query_pieces = dataset['text'].split("->")
        running_message = ""
        for piece in query_pieces:
            running_message += piece + "->"

            top, _, _ = get_together_completion(model_url, prompt, max_tokens=1, logprobs=0, n=1, echo=False)

            if get_logprobs:
                _, _, response = get_together_completion(model_url, prompt + " True", max_tokens=1, logprobs=1, n=1, echo=True)
                t_logprob = response['prompt'][0]['logprobs']['token_logprobs'][-1]
                _, _, response = get_together_completion(model_url, prompt + " False", max_tokens=1, logprobs=1, n=1, echo=True)
                f_logprob = response['prompt'][0]['logprobs']['token_logprobs'][-1]
            else:
                t_logprob = -1
                f_logprob = -1

            output['top_ans'].append(top)
            output['mass_ans'].append(t_logprob > f_logprob)
            output['raw_true_mass'].append(t_logprob)
            output['raw_false_mass'].append(f_logprob)
        
        output_df = pd.DataFrame.from_dict(output)
        output_df.to_csv(f'./results/raw_results/{uid}/{uid}_{concept}.csv')
        
    print("Done evaluating!")
    
def process_reply(objects, reply):
    answers = []
    for obj in objects:
        objstring = format_shape(obj)
        regex = f"{objstring[1:]}" + "\s*(?:->|:)\s*(\w+)" + r"\b"
        match = re.search(regex, reply)
        if match is not None:
            answers.append(match.group(1))
        else:
            answers.append("None")
    return answers


def get_chat_inputs(data: Tuple[List[List], List[List]]):
    instruction = "Learn the secret rule to label the objects in groups correctly. " +\
        "The rule may consider the color, size and shape of objects, and may also consider the other objects in each group. " +\
        "If an object in a group follows the rule, it should be labeled 'True'. " +\
        "Otherwise it should be labeled 'False'. Be concise and always follow the arrow '->' with a object's label.\n\n"

    all_inputs = []
    running_message = [{"role": 'system', "content":  instruction}] 
    i = 0

    for objects, answers in zip(*data):
        running_message.append(
                {'role': 'user',
                'content': f"Label the following objects in Group {i+1}:\n" +\
                          "\n".join(["-" + format_shape(obj) for obj in objects])
                
                 })

        all_inputs.append(copy.deepcopy(running_message))

        running_message.append(
                {'role': 'assistant',
                'content': f"The labels for the objects in Group {i+1} are:\n" +\
                           "\n".join(["-" + format_shape(obj) + f"-> {answer}" for obj, answer in zip(objects, answers)])
                })
        i += 1

    return all_inputs


def query_chatcompletion(model_id: str, raw_data: Dict, uid: str, log:str = None, setstop: int = 25):
    """
    :param Dict raw_data: Needs input generated by `process_concept_folders` from `preprocess.py`
    """
    if not os.path.isdir(f'./results/raw_results/{uid}'):
        os.mkdir(f'./results/raw_results/{uid}')

    for concept in tqdm(list(raw_data.keys()), total=len(list(raw_data.keys()))):
        replies = []
        top_ans = []
        data = (raw_data[concept]['sets'][:setstop], raw_data[concept]['answers'][:setstop])

        chat_inputs = get_chat_inputs(data)
        for i, chat_input in enumerate(chat_inputs):
            num_objects_in_set = len(chat_input[-1]['content'].split("-")) - 1 
            reply, _, _ = get_chatcompletion(chat_input, model=model_id)
            replies += [reply] * num_objects_in_set # duplicate reply for all objects in set
            top_ans += process_reply(data[0][i], reply) # get list of replies for each object

        column_dict = {
            'concept': [concept] * len(replies),
            'model_reply': replies,
            'top_ans': top_ans,
            }

        output_df = pd.DataFrame.from_dict(column_dict)
        output_df.to_csv(f'./results/raw_results/{uid}/{uid}_{concept}.csv')

        if log is not None:
            with open(log, 'a+') as f:
                for chat_input in chat_inputs:
                    json.dump(chat_input, f)
                    f.write("\n")

    print("Done evaluating!")

if __name__ == "__main__":

    import time
    import datasets

    timestamp =  str(time.time()).split(".")[0][-5:]

    """
    Sample of querying GPT4
    """
    # with open("./data/labels_to_data.json", 'r') as f:
    #     all_data = json.load(f)

    # L2_data = {k: d["L2"] for k, d in all_data.items() if k in ["hg02"]}
    # query_chatcompletion("gpt-4-1106-preview", L2_data, uid="gpt4_test", setstop=2)


